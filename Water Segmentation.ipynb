{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9304165,"sourceType":"datasetVersion","datasetId":5633947}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport tensorflow as tf\nimport os\nimport cv2\nimport tifffile as tiff\nimport tensorflow.image as tfi\nfrom PIL import Image\ntf.debugging.set_log_device_placement(True)\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras import layers,models, Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import TensorBoard\nfrom keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, SpatialDropout2D, BatchNormalization\nfrom tensorflow.keras.layers import Lambda\nfrom pathlib import Path\nfrom tensorflow.keras.utils import load_img, img_to_array, plot_model\nfrom sklearn.decomposition import PCA\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose","metadata":{"execution":{"iopub.status.busy":"2024-09-04T21:44:27.950372Z","iopub.execute_input":"2024-09-04T21:44:27.950710Z","iopub.status.idle":"2024-09-04T21:44:32.170285Z","shell.execute_reply.started":"2024-09-04T21:44:27.950676Z","shell.execute_reply":"2024-09-04T21:44:32.169335Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def load_images_pillow(folder_path):\n    images = []\n    for filename in os.listdir(folder_path):\n        if \"_\" not in filename:\n            if filename.endswith('.png') or filename.endswith('.jpg'):\n                img_path = os.path.join(folder_path, filename)\n                img = Image.open(img_path)\n                img_array = np.array(img)\n                images.append(img_array)\n    return images","metadata":{"execution":{"iopub.status.busy":"2024-09-04T21:44:41.841373Z","iopub.execute_input":"2024-09-04T21:44:41.841761Z","iopub.status.idle":"2024-09-04T21:44:41.848368Z","shell.execute_reply.started":"2024-09-04T21:44:41.841727Z","shell.execute_reply":"2024-09-04T21:44:41.847311Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def convert_to_pca(image):\n    images = image.reshape(-1, 12)\n    images = np.array(images, dtype=np.float32)\n    \n    pca = PCA(n_components=3)\n    images_pca = pca.fit_transform(images)\n    images = images_pca.reshape(128, 128, 3)\n    images = (images - np.min(images)) / (np.max(images) - np.min(images))\n    return images","metadata":{"execution":{"iopub.status.busy":"2024-09-04T21:44:43.214885Z","iopub.execute_input":"2024-09-04T21:44:43.215414Z","iopub.status.idle":"2024-09-04T21:44:43.221240Z","shell.execute_reply.started":"2024-09-04T21:44:43.215373Z","shell.execute_reply":"2024-09-04T21:44:43.220174Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def unet_model(n_filters=64, input_size= (128,128,12)):\n    \n    input_layer = Input(shape=(128, 128, 12))\n    \n    # Encoder\n    conv1 = Conv2D(64, 3, activation='relu', padding='same' ,kernel_initializer='he_normal')(input_layer)\n    b1 = BatchNormalization()(conv1)\n    conv2 = Conv2D(64, 3, activation='relu', padding='same' ,kernel_initializer='he_normal')(b1)\n    b2 = BatchNormalization()(conv2)\n\n    pool1 = MaxPooling2D(pool_size=(2, 2))(b2)\n\n    conv3 = Conv2D(64, 3, activation='relu', padding='same' ,kernel_initializer='he_normal')(pool1)\n    b3 = BatchNormalization()(conv3)\n    conv4 = Conv2D(64, 3, activation='relu', padding='same' ,kernel_initializer='he_normal')(b3)\n    b4 = BatchNormalization()(conv4)\n\n    pool2 = MaxPooling2D(pool_size=(2, 2))(b4)\n\n    conv5 = Conv2D(256, 3, activation='relu', padding='same' ,kernel_initializer='he_normal')(pool2)\n    b5 = BatchNormalization()(conv5)\n    conv6 = Conv2D(256, 3, activation='relu', padding='same' ,kernel_initializer='he_normal')(b5)\n    b6 = BatchNormalization()(conv6)\n\n    pool3 = MaxPooling2D(pool_size=(2, 2))(b6)\n\n    conv7 = Conv2D(512, 3, activation='relu', padding='same' ,kernel_initializer='he_normal')(pool3)\n    b7 = BatchNormalization()(conv7)\n    conv8 = Conv2D(512, 3, activation='relu', padding='same' ,kernel_initializer='he_normal')(b7)\n    b8 = BatchNormalization()(conv8)\n\n    pool4 = MaxPooling2D(pool_size=(2, 2))(b8)\n    \n    #Bottleneck\n    conv9 = Conv2D(1024, 3, activation='relu', padding='same' ,kernel_initializer='he_normal')(pool4)\n    b9 = BatchNormalization()(conv9)\n    conv10 = Conv2D(1024, 3, activation='relu', padding='same' ,kernel_initializer='he_normal')(b9)\n    b10 = BatchNormalization()(conv10)\n\n    \n    #Decoder\n    up1 = UpSampling2D()(b10)\n    up1 = Conv2D(filters= 512, kernel_size=(2,2), activation='relu', padding='same' ,kernel_initializer='he_normal')(up1)\n    merge1 = concatenate([conv8, up6])  # Ensure Concatenate is used with keyword arguments\n    \n    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)\n    drop6 = BatchNormalization()(conv6)\n    conv6 = Conv2D(512, 3, activation='relu', padding='same')(drop6)\n    \n    up7 = UpSampling2D(size=(2, 2))(conv6)\n    up7 = Conv2D(256, 2, activation='relu', padding='same')(up7)\n    merge7 = concatenate([conv6, up7])\n    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)\n    drop7 = BatchNormalization()(conv7)\n    conv7 = Conv2D(256, 3, activation='relu', padding='same')(drop7)\n\n    up8 = UpSampling2D(size=(2, 2))(conv7)\n    up8 = Conv2D(128, 2, activation='relu', padding='same')(up8)\n    merge8 = concatenate([conv2, up8])\n    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)\n    drop8 = BatchNormalization()(conv8)\n    conv8 = Conv2D(128, 3, activation='relu', padding='same')(drop8)\n\n    up9 = UpSampling2D(size=(2, 2))(conv8)\n    up9 = Conv2D(64, 2, activation='relu', padding='same')(up9)\n    merge9 = concatenate([conv1, up9])\n    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)\n    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)    \n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n    model = Model(inputs=input_layer, outputs=conv10)\n\n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"u_net_model=unet_model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(u_net_model, \"UNet.png\", show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"u_net_model.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_path = \"/kaggle/input/water-segmentation/data/images/*.tif\"\nlabels_path = \"/kaggle/input/water-segmentation/data/labels\"\n\nimages = tiff.imread(images_path)\nlabels = load_images_pillow(labels_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[len(labels) , len(images)]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,6))\nfig, axs = plt.subplots(1, 2, figsize=(16, 8), constrained_layout=True)\naxs[0].imshow(labels[205])\naxs[1].imshow(convert_to_pca((images[205])))\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_datagen = ImageDataGenerator(\n#     rescale=1./255,\n#     rotation_range=40,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     shear_range=0.2,\n#     zoom_range=0.2,\n#     horizontal_flip=True,\n#     fill_mode='nearest'\n# )\n\n# val_datagen = ImageDataGenerator(rescale=1./255)\n\n# test_datagen = ImageDataGenerator(rescale=1./255)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(images, labels, test_size= .1, random_state= 42)\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size= .1, random_state= 42)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# labels= tf.convert_to_tensor(labels)\n# images= tf.convert_to_tensor(images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_generator = train_datagen.flow(\n#     x= X_train,\n#     y= y_train,\n#     batch_size=32,\n# )\n\n# valid_generator = train_datagen.flow(\n#     x= X_valid,\n#     y= y_valid,\n#     batch_size=32,\n# )\n\n# test_datagen_generator = train_datagen.flow(\n#     x= X_test,\n#     y= y_test,\n#     batch_size=32,\n#     shuffle= False\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"u_net_model.compile(optimizer=tf.keras.optimizers.Adam(),\n                   loss='binary_crossentropy',\n                   metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create checkpoint callback\ncheckpoint_path = \"model_checkpoint.keras\"\ncheckpoint_callback = ModelCheckpoint(checkpoint_path,\n                                      monitor=\"val_accuracy\",\n                                      save_best_only=True)\n\n# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\nearly_stopping = EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n                               patience = 10,\n                               restore_best_weights = True) # if val loss decreases for 3 epochs in a row, stop training\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\ntarget_size = (128, 128)\n\n# Convert numpy arrays to TensorFlow datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\nval_dataset = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\ntest_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n\n# Shuffle, batch, and prefetch the datasets\nbatch_size = 32\ntrain_dataset = train_dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\nval_dataset = val_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\ntest_dataset = test_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x_batch, y_batch in train_dataset:\n    print(x_batch.shape, y_batch.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps_per_epoch = len(X_train) // batch_size\nvalidation_steps = len(X_valid) // batch_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = u_net_model.fit(\n    train_dataset,\n    epochs=150,\n    validation_data= valid_generator,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps,\n    callbacks=[\n        early_stopping,\n        reduce_lr, \n        checkpoint_callback\n    ]\n )","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = u_net_model.evaluate(test_dataset , verbose=0)\n\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trash\n","metadata":{}},{"cell_type":"code","source":"# def read_label(path, size= 128):\n#     label = load_img(path)\n# #     label = img_to_array(label)\n# #     label = cv2.cvtColor(label, cv2.COLOR_RGB2GRAY)\n#     label = tf.convert_to_tensor(label, dtype= tf.float32)\n# #     label = tf.cast(label, tf.float32)\n#     label *= 255.\n#     label = tf.convert_to_tensor(label, dtype= tf.float32)\n#     return label","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#     inputs = tf.keras.layers.Input((128,128,3))\n    \n#     cblock1 = conv_block(inputs, num_filters= n_filters)\n#     cblock2 = conv_block(cblock1[0], num_filters= n_filters*2)\n#     cblock3 = conv_block(cblock2[0], num_filters= n_filters*4)\n#     cblock4 = conv_block(cblock3[0], num_filters= n_filters*8)\n#     cblock5 = conv_block(cblock4[0], num_filters= n_filters*16, Max_pool=0)\n    \n    \n#     ublock6 = upsampling_block(cblock5[0], cblock4[1],  n_filters * 8)\n#     ublock7 = upsampling_block(ublock6, cblock3[1],  n_filters * 4)\n#     ublock8 = upsampling_block(ublock7, cblock2[1],  n_filters * 2)\n#     ublock9 = upsampling_block(ublock8, cblock1[1],  n_filters)\n\n#     conv9 = tf.keras.layers.Conv2D(n_filters,3,\n#                  activation='relu',\n#                  padding='same',\n#                  kernel_initializer='he_normal')(ublock9)\n    \n    \n#     conv10 = tf.keras.layers.Conv2D(3, kernel_size=3, padding=\"same\",activation = 'sigmoid')(conv9)\n#     model = tf.keras.Model(inputs=inputs, outputs=conv10)\n#     return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input_folder = \"/kaggle/input/water-segmentation/data/labels\"\n# output_folder = '/kaggle/working/labels'\n# os.makedirs(output_folder, exist_ok=True)\n\n# for filename in os.listdir(input_folder):\n#     if filename.endswith('.png') or filename.endswith('.jpg'):\n#         # Open image file\n#         img = Image.open(os.path.join(input_folder, filename))\n#         # Convert image to grayscale\n#         gray_img = img.convert('L')\n#         # Save image with new dimensions\n#         gray_img = gray_img.resize((128, 128))\n#         gray_img = gray_img.convert('L')  # Ensure it's grayscale\n#         gray_img.save(os.path.join(output_folder, filename))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# images = tiff.imread(images_path)\n# # labels = read_label(os.path.join(labels_path, x)) for x in os.listdir(labels_path) if \"_\" not in x\n# i = 0\n# labels \n# for x in os.listdir(labels_path):\n#     if \"_\" not in x:\n#         labels[i] = ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# from tensorflow.image import resize\n\n# def data_generator(images, labels, batch_size, target_size=(128, 128)):\n#     while True:\n#         for start in range(0, len(images), batch_size):\n#             end = min(start + batch_size, len(images))\n#             X_batch = images[start:end]\n#             y_batch = labels[start:end]\n\n#             # Resize images and labels to the target size\n#             X_batch_resized = np.array([resize(img, target_size) for img in X_batch])\n#             y_batch_resized = np.array([resize(lbl, target_size) for lbl in y_batch])\n\n#             # Normalize images\n#             X_batch_resized = X_batch_resized / 255.0\n\n#             # Ensure labels have the correct shape (e.g., for binary segmentation)\n#             if y_batch_resized.ndim == 4 and y_batch_resized.shape[-1] != 1:\n#                 y_batch_resized = np.expand_dims(y_batch_resized[..., 0], axis=-1)\n\n#             yield X_batch_resized, y_batch_resized\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# labels = np.array(labels, dtype=np.float32)\n# labels = np.array([cv2.cvtColor(label, cv2.COLOR_RGB2GRAY) for label in labels])\n# for label in range(len(labels)):\n#     labels[label] = np.array(labels[label], dtype=np.float32)\n#     labels[label] = cv2.cvtColor(labels[label], cv2.COLOR_RGB2GRAY)\n    \n\n# # Optionally, add a channel dimension back if needed (to match the U-Net input/output shape)\n# labels = np.expand_dims(labels, axis=-1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batch_size = 32\n# target_size = (128, 128)  # Make sure this matches the output size of your model\n\n# # Create generators\n# train_generator = train_generator(X_train, y_train, batch_size, target_size)\n# val_generator = val_generator(X_valid, y_valid, batch_size, target_size)\n# test_generator = test_generator(X_test, y_test, batch_size, target_size)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}